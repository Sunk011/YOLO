# -*- coding: utf-8 -*-
"""
è¾“å…¥æŒ‡å®šçš„å›¾åƒç›®å½•å’Œæ ‡æ³¨ç›®å½•ï¼Œæ£€æŸ¥å®ƒä»¬ä¹‹é—´çš„å¯¹åº”å…³ç³»ï¼ŒéªŒè¯æ ‡æ³¨æ–‡ä»¶æ ¼å¼çš„æ­£ç¡®æ€§ï¼Œå¹¶ç”Ÿæˆè¯¦ç»†çš„æ£€æŸ¥æŠ¥å‘Šã€‚
Author: sunkang
Date: 2025-09-15
"""
import os
import cv2
import re
import random
from datetime import datetime  # æ›¿æ¢os.popen('date')ï¼Œè·¨å¹³å°å…¼å®¹

def validate_yolo_dataset(images_dir, labels_dir, max_class_id=None, report_path=None):
    """
    æ£€æŸ¥YOLOæ ¼å¼æ•°æ®é›†çš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§
    
    Args:
        images_dir: å›¾åƒç›®å½•è·¯å¾„
        labels_dir: æ ‡æ³¨ç›®å½•è·¯å¾„
        max_class_id: æœ€å¤§ç±»åˆ«IDï¼ˆå¯é€‰ï¼Œä¾‹å¦‚4ç±»åˆ™è®¾ä¸º3ï¼Œè®¾ä¸ºNoneåˆ™ä¸æ£€æŸ¥ï¼‰
        report_path: ä¿å­˜æŠ¥å‘Šçš„è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æœæœªæŒ‡å®šåˆ™ä¿å­˜åˆ°å›¾åƒç›®å½•çš„ä¸Šçº§ç›®å½•ï¼‰
    
    Returns:
        dict: åŒ…å«æ£€æŸ¥ç»“æœçš„å­—å…¸
    """
    
    # å›¾åƒæ–‡ä»¶æ‰©å±•å
    image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.JPG', '.PNG')
    
    # è®°å½•æ‰€æœ‰é”™è¯¯
    all_errors = []
    
    # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…YOLOæ ‡æ³¨è¡Œï¼ˆclass_id + 4ä¸ªæµ®ç‚¹æ•°ï¼‰
    yolo_line_pattern = re.compile(r'^\s*(\d+)\s+([\d.]+)\s+([\d.]+)\s+([\d.]+)\s+([\d.]+)\s*$')
    
    print(f"å¼€å§‹æ£€æŸ¥æ•°æ®é›†:")
    print(f"å›¾åƒç›®å½•: {images_dir}")
    print(f"æ ‡æ³¨ç›®å½•: {labels_dir}\n")
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(images_dir):
        error = f"é”™è¯¯: å›¾åƒç›®å½•ä¸å­˜åœ¨ - {images_dir}"
        print(error)
        return {"success": False, "error": error, "report_path": None}
        
    if not os.path.exists(labels_dir):
        error = f"é”™è¯¯: æ ‡æ³¨ç›®å½•ä¸å­˜åœ¨ - {labels_dir}"
        print(error)
        return {"success": False, "error": error, "report_path": None}
    
    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶å’Œæ ‡æ³¨æ–‡ä»¶
    image_files = [f for f in os.listdir(images_dir) if f.endswith(image_extensions)]
    label_files = [f for f in os.listdir(labels_dir) if f.endswith('.txt')]
    
    print(f"å›¾åƒæ–‡ä»¶æ•°é‡: {len(image_files)}")
    print(f"æ ‡æ³¨æ–‡ä»¶æ•°é‡: {len(label_files)}\n")
    
    # è®°å½•å„æ–‡ä»¶å¤¹æ–‡ä»¶æ•°é‡
    folder_counts = {
        "images": len(image_files),
        "labels": len(label_files)
    }
    
    # æå–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ç”¨äºåŒ¹é…
    image_basenames = {os.path.splitext(f)[0] for f in image_files}
    label_basenames = {os.path.splitext(f)[0] for f in label_files}
    
    # 1. æ£€æŸ¥å›¾åƒä¸æ ‡æ³¨æ–‡ä»¶çš„å¯¹åº”æ€§
    images_without_label = image_basenames - label_basenames
    labels_without_image = label_basenames - image_basenames
    
    correspondence_info = {
        "total_images": len(image_files),
        "total_labels": len(label_files),
        "matched_pairs": len(image_basenames & label_basenames),
        "images_without_label": list(images_without_label),
        "labels_without_image": list(labels_without_image)
    }
    
    if images_without_label:
        error = f"è­¦å‘Š: {len(images_without_label)}ä¸ªå›¾åƒæ²¡æœ‰å¯¹åº”æ ‡æ³¨æ–‡ä»¶"
        print(error)
        all_errors.append(error)
        all_errors.extend([f"  - {f}.*" for f in sorted(images_without_label)[:5]])
    
    if labels_without_image:
        error = f"è­¦å‘Š: {len(labels_without_image)}ä¸ªæ ‡æ³¨æ–‡ä»¶æ²¡æœ‰å¯¹åº”å›¾åƒ"
        print(error)
        all_errors.append(error)
        all_errors.extend([f"  - {f}.txt" for f in sorted(labels_without_image)[:5]])
    
    # 2. æ£€æŸ¥å›¾åƒæ–‡ä»¶å®Œæ•´æ€§ï¼ˆéšæœºæŠ½æŸ¥ï¼‰
    broken_images = []
    sample_size = min(100, len(image_files))
    sampled_images = random.sample(image_files, sample_size) if image_files else []
    
    for img_file in sampled_images:
        img_path = os.path.join(images_dir, img_file)
        try:
            img = cv2.imread(img_path)
            if img is None:
                broken_images.append(img_file)
        except Exception:
            broken_images.append(img_file)
    
    if broken_images:
        error = f"è­¦å‘Š: {len(broken_images)}ä¸ªå›¾åƒæ–‡ä»¶æŸåæˆ–æ— æ³•æ‰“å¼€"
        print(error)
        all_errors.append(error)
        all_errors.extend([f"  - {f}" for f in broken_images[:5]])
    
    # 3. æ£€æŸ¥æ ‡æ³¨æ–‡ä»¶æ ¼å¼
    invalid_annotations = []
    for label_file in label_files:
        label_path = os.path.join(labels_dir, label_file)
        try:
            with open(label_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # æ£€æŸ¥ç©ºæ ‡æ³¨æ–‡ä»¶
            if not any(line.strip() for line in lines):
                invalid_annotations.append(f"{label_file} (ç©ºæ–‡ä»¶)")
                continue
            
            # æ£€æŸ¥æ¯è¡Œæ ¼å¼
            for line_num, line in enumerate(lines, 1):
                line = line.strip()
                if not line:
                    continue
                
                match = yolo_line_pattern.match(line)
                if not match:
                    invalid_annotations.append(
                        f"{label_file} (ç¬¬{line_num}è¡Œæ ¼å¼é”™è¯¯: '{line}')"
                    )
                    continue
                
                # æ£€æŸ¥åæ ‡èŒƒå›´
                class_id = int(match.group(1))
                cx, cy, w, h = map(float, match.groups()[1:])
                
                if not (0 <= cx <= 1 and 0 <= cy <= 1 and 0 <= w <= 1 and 0 <= h <= 1):
                    invalid_annotations.append(
                        f"{label_file} (ç¬¬{line_num}è¡Œåæ ‡è¶…å‡º0-1èŒƒå›´)"
                    )
                
                # æ£€æŸ¥ç±»åˆ«ID
                if max_class_id is not None and class_id > max_class_id:
                    invalid_annotations.append(
                        f"{label_file} (ç¬¬{line_num}è¡Œç±»åˆ«ID {class_id} è¶…è¿‡æœ€å¤§å…è®¸å€¼ {max_class_id})"
                    )
                elif class_id < 0:
                    invalid_annotations.append(
                        f"{label_file} (ç¬¬{line_num}è¡Œç±»åˆ«IDä¸ºè´Ÿæ•°: {class_id})"
                    )
        
        except Exception as e:
            invalid_annotations.append(f"{label_file} (è¯»å–é”™è¯¯: {str(e)})")
    
    if invalid_annotations:
        error = f"è­¦å‘Š: {len(invalid_annotations)}ä¸ªæ ‡æ³¨æ–‡ä»¶æ ¼å¼é”™è¯¯"
        print(error)
        all_errors.append(error)
        all_errors.extend([f"  - {err}" for err in invalid_annotations[:5]])
    
    print("æ£€æŸ¥å®Œæˆ\n")
    
    # è¾“å‡ºæ–‡ä»¶æ•°é‡æ±‡æ€»å’Œå¯¹åº”å…³ç³»
    print("===== æ–‡ä»¶æ•°é‡å’Œå¯¹åº”å…³ç³»æ±‡æ€» =====")
    print(f"å›¾åƒæ–‡ä»¶æ•°é‡: {correspondence_info['total_images']}")
    print(f"æ ‡æ³¨æ–‡ä»¶æ•°é‡: {correspondence_info['total_labels']}")
    print(f"åŒ¹é…çš„æ–‡ä»¶å¯¹æ•°: {correspondence_info['matched_pairs']}")
    print(f"æ— æ ‡æ³¨çš„å›¾åƒæ•°: {len(correspondence_info['images_without_label'])}")
    print(f"æ— å›¾åƒçš„æ ‡æ³¨æ•°: {len(correspondence_info['labels_without_image'])}")
    print()
    
    # ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š
    print("===== æ•°æ®é›†æ£€æŸ¥æ€»ç»“ =====")
    success = len(all_errors) == 0
    
    if success:
        print("æ­å–œï¼æ•°æ®é›†æ£€æŸ¥é€šè¿‡ï¼Œæœªå‘ç°é—®é¢˜ã€‚")
    else:
        print(f"å…±å‘ç°{len(all_errors)}ä¸ªé—®é¢˜ï¼š")
        for i, error in enumerate(all_errors, 1):
            print(f"{i}. {error}")
    
    # ç¡®å®šæŠ¥å‘Šä¿å­˜è·¯å¾„
    if report_path is None:
        # å¦‚æœæœªæŒ‡å®šæŠ¥å‘Šè·¯å¾„ï¼Œä¿å­˜åˆ°å›¾åƒç›®å½•çš„ä¸Šçº§ç›®å½•
        parent_dir = os.path.dirname(images_dir)
        report_path = os.path.join(parent_dir, "dataset_validation_report.txt")
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°æ–‡ä»¶
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write("æ•°æ®é›†æ£€æŸ¥æŠ¥å‘Š\n")
        f.write("=" * 50 + "\n")
        f.write(f"æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"å›¾åƒç›®å½•: {images_dir}\n")
        f.write(f"æ ‡æ³¨ç›®å½•: {labels_dir}\n")
        f.write(f"æœ€å¤§ç±»åˆ«ID: {max_class_id if max_class_id is not None else 'æœªé™åˆ¶'}\n\n")
        
        f.write("æ–‡ä»¶æ•°é‡ç»Ÿè®¡ï¼š\n")
        f.write(f"å›¾åƒæ–‡ä»¶æ•°é‡: {correspondence_info['total_images']}\n")
        f.write(f"æ ‡æ³¨æ–‡ä»¶æ•°é‡: {correspondence_info['total_labels']}\n")
        f.write(f"åŒ¹é…çš„æ–‡ä»¶å¯¹æ•°: {correspondence_info['matched_pairs']}\n")
        f.write(f"æ— æ ‡æ³¨çš„å›¾åƒæ•°: {len(correspondence_info['images_without_label'])}\n")
        f.write(f"æ— å›¾åƒçš„æ ‡æ³¨æ•°: {len(correspondence_info['labels_without_image'])}\n\n")
        
        if correspondence_info['images_without_label']:
            f.write("æ— æ ‡æ³¨çš„å›¾åƒæ–‡ä»¶ï¼š\n")
            for img in correspondence_info['images_without_label']:
                f.write(f"  - {img}.*\n")
            f.write("\n")
        
        if correspondence_info['labels_without_image']:
            f.write("æ— å›¾åƒçš„æ ‡æ³¨æ–‡ä»¶ï¼š\n")
            for label in correspondence_info['labels_without_image']:
                f.write(f"  - {label}.txt\n")
            f.write("\n")
        
        f.write("é—®é¢˜åˆ—è¡¨ï¼š\n")
        if not all_errors:
            f.write("æœªå‘ç°é—®é¢˜\n")
        else:
            for i, error in enumerate(all_errors, 1):
                f.write(f"{i}. {error}\n")
    
    print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")
    
    # è¿”å›æ£€æŸ¥ç»“æœ
    result = {
        "success": success,
        "report_path": report_path,
        "correspondence_info": correspondence_info,
        "error_count": len(all_errors),
        "errors": all_errors
    }
    
    return result

if __name__ == "__main__":
    # ç¤ºä¾‹ä½¿ç”¨æ–¹å¼
    # æ–¹å¼1: ç›´æ¥æŒ‡å®šå›¾åƒå’Œæ ‡æ³¨ç›®å½•
    images_dir = "/home/sk/datasets/car_vis_v2/images/train"  # å›¾åƒç›®å½•è·¯å¾„
    labels_dir = "/home/sk/datasets/car_vis_v2/labels/train"  # æ ‡æ³¨ç›®å½•è·¯å¾„
    max_class_id = 3  # æœ€å¤§ç±»åˆ«IDï¼ˆä¾‹å¦‚4ç±»åˆ™è®¾ä¸º3ï¼Œè®¾ä¸ºNoneåˆ™ä¸æ£€æŸ¥ç±»åˆ«èŒƒå›´ï¼‰
    report_path = "/home/sk/datasets/car_vis_v2/validation_report.txt"  # æŠ¥å‘Šä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    
    # æ–¹å¼2: æ£€æŸ¥æ•´ä¸ªæ•°æ®é›†çš„trainå’Œvalé›†åˆ
    # å¦‚æœè¦æ£€æŸ¥å®Œæ•´æ•°æ®é›†ï¼Œå¯ä»¥åˆ†åˆ«è°ƒç”¨trainå’Œval
    
    print("æ­£åœ¨æ£€æŸ¥è®­ç»ƒé›†...")
    result = validate_yolo_dataset(images_dir, labels_dir, max_class_id, report_path)
    
    if result["success"]:
        print(f"âœ… æ•°æ®é›†æ£€æŸ¥é€šè¿‡ï¼")
    else:
        print(f"âŒ å‘ç° {result['error_count']} ä¸ªé—®é¢˜")
    
    print(f"ğŸ“Š å¯¹åº”å…³ç³»ç»Ÿè®¡:")
    print(f"   åŒ¹é…æ–‡ä»¶å¯¹: {result['correspondence_info']['matched_pairs']}")
    print(f"   æ— æ ‡æ³¨å›¾åƒ: {len(result['correspondence_info']['images_without_label'])}")
    print(f"   æ— å›¾åƒæ ‡æ³¨: {len(result['correspondence_info']['labels_without_image'])}")
    print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {result['report_path']}")
    
    # å¦‚æœéœ€è¦æ£€æŸ¥éªŒè¯é›†ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Š
    # print("\n" + "="*50)
    # print("æ­£åœ¨æ£€æŸ¥éªŒè¯é›†...")
    # val_images_dir = "/home/sk/datasets/car_vis_v2/images/val"
    # val_labels_dir = "/home/sk/datasets/car_vis_v2/labels/val"
    # val_report_path = "/home/sk/datasets/car_vis_v2/val_validation_report.txt"
    # val_result = validate_yolo_dataset(val_images_dir, val_labels_dir, max_class_id, val_report_path)
    
    # print(f"ğŸ“„ éªŒè¯é›†æŠ¥å‘Š: {val_result['report_path']}")